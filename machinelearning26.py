# -*- coding: utf-8 -*-
"""MACHINELEARNING26

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fU4dkfJnEW8tkNWFt4LJ-kSAKmrwm3G8
"""

#Project of ML
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# üé¨ Movie Success Prediction
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.model_selection import train_test_split,learning_curve
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (accuracy_score,confusion_matrix,classification_report,
                             roc_curve,auc,precision_recall_curve)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.svm import SVC

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#1Ô∏è‚É£ Create Dataset
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

df = pd.read_csv("movie_data (1).csv")

#------------------------------------
#2Ô∏è‚É£Encoding
#------------------------------------
le = LabelEncoder()
for col in ['Genre','Release_Season','Status']:
    df[col] = le.fit_transform(df[col])

#------------------------------------
#3Ô∏è‚É£ Attractive Visualizations
#------------------------------------

# Count Plot
plt.figure()
sns.countplot(x=df['Status'])
plt.title("Movie Status Distribution (0=Flop, 1=Hit)")
plt.show()

#Box Plot
plt.figure()
sns.boxplot(x=df['Status'],y=df['Budget'])
plt.title("Budget vs Movie status")
plt.show()

#Correlation Heatmap
plt.figure()
sns.heatmap(df.corr(),annot=True)
plt.title("Correlation Heatmap")
plt.show()

#--------------------------------------------
#4Ô∏è‚É£ Train-Test Split
#--------------------------------------------

x = df.drop('Status',axis=1)
y = df['Status']

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)

# ---------------------------------------
# 5Ô∏è‚É£ Train Multiple Models
#----------------------------------------

models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "SVM": SVC(probability=True),
    "Gradient Boost": GradientBoostingClassifier()
}
accuracies = {}
roc_data = {}

for name,model in models.items():
    model.fit(x_train,y_train)
    y_pred = model.predict(x_test)
    acc = accuracy_score(y_test,y_pred)
    accuracies[name] = acc

    y_prob = model.predict_proba(x_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test,y_prob)
    roc_auc = auc(fpr,tpr)
    roc_data[name] = (fpr, tpr, roc_auc)

    print(f"\n{name} Accuracy:", acc)

    # -----------------------------------------
    # 6Ô∏è‚É£ Accuracy Comparison Graph
    # -----------------------------------------

    plt.figure()
    plt.bar(accuracies.keys(), accuracies.values())
    plt.xticks(rotation=45)
    plt.title("Model Accuracy Comparison")
    plt.ylabel("Accuracy")
    plt.show()

    #---------------------------------------------
    #7Ô∏è‚É£ ROC curve
    #---------------------------------------------


    plt.figure()
    for name, (fpr, tpr, roc_auc) in roc_data.items():
      plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")


    plt.plot([0,1],[0,1],linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve Comparison")
    plt.legend()
    plt.show()


    # ----------------------------------
    # 8Ô∏è‚É£ Select Best Model
    # ----------------------------------

    best_model_name = max(accuracies, key=accuracies.get)
    best_model = models[best_model_name]

    print("\nBest Model:",best_model_name)


    # -----------------------------------
    # 9Ô∏è‚É£ Confusion Matrix
    # -----------------------------------

    y_pred = best_model.predict(x_test)
    cm = confusion_matrix(y_test,y_pred)

    plt.figure()
    sns.heatmap(cm, annot=True, fmt="d")
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()



    # ------------------------------
    # üîü Feature Importance (if available)
    # ------------------------------

    if hasattr(best_model, 'feature_importances_'):
       plt.figure()
       plt.barh(x.columns, best_model.feature_importances_)
       plt.title("Feature Importance")
       plt.show()

    # --------------------------
    # 1Ô∏è‚É£1Ô∏è‚É£ Learning Curve
    # --------------------------

    train_sizes, train_scores, val_scores = learning_curve(
        best_model, x, y, cv=5)
    plt.figure()
    plt.plot(train_sizes, np.mean(train_scores, axis=1)),
    plt.title("Learning Curve")
    plt.xlabel("Training Examples")
    plt.ylabel("Score")
    plt.show()


    # ----------------------------
    #     Precision-Recall Curve
    # ----------------------------

    y_prob = best_model.predict_proba(x_test)[:,1]
    precision, recall, _ = precision_recall_curve(y_test, y_prob)

    plt.figure()
    plt.plot(recall, precision)
    plt.title("Precision-Recall Curve")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.show()

    # -------------------------------
    #     Save Best Model
    # -------------------------------

    joblib.dump(best_model, "best_model.pkl")
    print("\nModel saved as best_model.pkl")

